{
  data_module: {
    type: map

    setup: {
      dataset_files: {
        train_data_path: "data/train_trx.parquet"
        test_data_path: "data/test_trx.parquet"
      }
      col_id: client_id
      col_id_dtype: str
      col_target: age

      split_by: embeddings_validation
      fold_info: "conf/embeddings_validation.work/folds/folds.json"
    }

    train: {
        min_seq_len: 0
        augmentations: [
            [SeqLenLimit, {max_seq_len: 800}]
            [DropoutTrx, {trx_dropout: 0.03}]
            # [DropDay, {}]
            # [RandomSlice, {min_len: 50, max_len: 150, rate_for_min: 0.9}]
            [AllTimeShuffle, {}]
        ]
        num_workers: 16
        batch_size: 32
    }

    valid: {
        augmentations: [
            [SeqLenLimit, {max_seq_len: 800}]
        ]
        num_workers: 8
        batch_size: 512
    }
  }

  embedding_validation_results: {
    model_name: nn
    feature_name: cpc_finetuning
    output_path: "results/cpc_finetuning_results.json"
  }

  seed_everything: 42
  trainer: {
    gpus: 1
    auto_select_gpus: false

    max_epochs: 8
    log_every_n_steps: 10

    checkpoint_callback: false
    deterministic: True
  }
  logger_name: cpc_finetuning

  params: {
    score_metric: [accuracy]

    encoder_type: pretrained,
    pretrained: {
        model_type: "CpcModule",
        model_path: "models/cpc_model.p"
        lr: 0.00001
        # lr: freeze
    }

    head_layers: [
        [BatchNorm1d, {num_features: "{seq_encoder.embedding_size}"}]
        [Linear, {"in_features": "{seq_encoder.embedding_size}", "out_features": 4}]
        [LogSoftmax, {dim: 1}]
    ]

    train: {
      loss: NLLLoss,
      lr: 0.001,
      weight_decay: 0.0,
    },
    lr_scheduler: {
      step_size: 1,
      step_gamma: 0.60
    }
  }
}
