{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет http://www.cs.cmu.edu/~enron/\n",
    "Уже скаченный и лежит в папке '/mnt/data/molchanov/datasets/maildir'\n",
    "\n",
    "! pip install mail-parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreamingGraph -  словарь графов (1 граф соответствует 1 дню) ключ - дата (день)\n",
    "Каждый граф - объект типа Graph, который хранит вершины и ребра (Edge) в виде списка смежности, \n",
    "что представляет из себя словарь словарей, ключи которых - имена нод графов в данном случае емэил адреса отправителя \n",
    "и получающего, например Graph['sender1@mail.ru']['reciver2@mail.ru'] это ребро, объект класса Edge - распарсенные письма\n",
    "между 'sender1@mail.ru' и 'reciver2@mail.ru' в течении дня. Edge - Хранит в себе словарь свойств, на данный момент там есть число \n",
    "писем и Subject письма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os import path as osp\n",
    "import tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "import datetime\n",
    "import mailparser\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "base_path = '/mnt/data/molchanov/datasets/maildir'\n",
    "MIN_YEAR = 1999\n",
    "MIN_DATE = datetime.datetime(1999, 7, 1)\n",
    "MAIL2NICK = dict()\n",
    "NICK2MAIL = dict()\n",
    "COUNTER = -1\n",
    "PERWEEK_AGGREGATION = True\n",
    "FILE_NAME = 'enron_graph_week.pickle' if PERWEEK_AGGREGATION else 'enron_graph_day.pickle'\n",
    "\n",
    "def mail2nick(mail):\n",
    "    global COUNTER\n",
    "    if mail in MAIL2NICK:\n",
    "        return MAIL2NICK[mail]\n",
    "    \n",
    "    COUNTER += 1\n",
    "    MAIL2NICK[mail] = str(COUNTER)\n",
    "    NICK2MAIL[str(COUNTER)] = mail\n",
    "    \n",
    "    return COUNTER\n",
    "\n",
    "def nickn_streaming_graph(stream_graph):\n",
    "    for date, graph in STREAMING_GRAPH.items():\n",
    "        for sender, recivers_dict in graph.items():\n",
    "            mail2nick(sender)\n",
    "            for reciver, sender_revicer_mail in recivers_dict.items():\n",
    "                mail2nick(reciver)\n",
    "            \n",
    "\n",
    "def jn(p1, p2):\n",
    "    return osp.join(p1, p2)\n",
    "\n",
    "def jnb(p):\n",
    "    return jn(base_path, p)\n",
    "\n",
    "def week_of_month(dt):\n",
    "    \"\"\" Returns the week of the month for the specified date.\n",
    "    \"\"\"\n",
    "\n",
    "    first_day = dt.replace(day=1)\n",
    "\n",
    "    dom = dt.day\n",
    "    adjusted_dom = dom + first_day.weekday()\n",
    "\n",
    "    return int(ceil(adjusted_dom/7.0))\n",
    "\n",
    "def count_mails(graph):\n",
    "    n = 0\n",
    "    for sender, recivers_dict in graph.items():\n",
    "        for reciver, sender_revicer_mail in recivers_dict.items():\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__dict__ = dict()\n",
    "\n",
    "    def __setitem__(self, key, item):\n",
    "        self.__dict__[key] = item\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.__dict__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__dict__)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        del self.__dict__[key]\n",
    "\n",
    "    def clear(self):\n",
    "        return self.__dict__.clear()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__dict__.copy()\n",
    "\n",
    "    def has_key(self, k):\n",
    "        return k in self.__dict__\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        return self.__dict__.update(*args, **kwargs)\n",
    "\n",
    "    def keys(self):\n",
    "        return self.__dict__.keys()\n",
    "\n",
    "    def values(self):\n",
    "        return self.__dict__.values()\n",
    "\n",
    "    def items(self):\n",
    "        return self.__dict__.items()\n",
    "\n",
    "    def pop(self, *args):\n",
    "        return self.__dict__.pop(*args)\n",
    "\n",
    "    def __cmp__(self, dict_):\n",
    "        return self.__cmp__(self.__dict__, dict_)\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self.__dict__\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.__dict__)\n",
    "\n",
    "    def __unicode__(self):\n",
    "        return unicode(repr(self.__dict__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Graph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge(Mapping):\n",
    "    \n",
    "    def __init__(self, d={}):\n",
    "        super().__init__()\n",
    "        self.__dict__ = d\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        cur = deepcopy(self)\n",
    "        for key, val in other.items():\n",
    "            if key in cur:\n",
    "                cur[key] += deepcopy(val)\n",
    "            else:\n",
    "                cur[key] = deepcopy(val)\n",
    "        return cur\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "def ddict():\n",
    "    return defaultdict(Edge)\n",
    "    \n",
    "class Graph(Mapping):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.__dict__ = defaultdict(lambda : defaultdict(Edge))\n",
    "        self.__dict__ = defaultdict(ddict)\n",
    "    \n",
    "    # srs - sourse mail addres\n",
    "    # dst - destination mail addres\n",
    "    # features - dict of key value features\n",
    "    def add_pair(self, srs, dst, features):\n",
    "        self[srs][dst] += Edge(features)\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "        \n",
    "\n",
    "class StreamingGraph(Mapping):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__dict__ = defaultdict(Graph)\n",
    "        \n",
    "    # date - mail date\n",
    "    # srs - sourse mail addres\n",
    "    # dst - destination mail addres\n",
    "    # features - dict of key value features\n",
    "    def add_pair(self, date, srs, dst, features):\n",
    "        self[date].add_pair(srs, dst, features)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "    \n",
    "def merge_streamin_graphs(lst_graphs):\n",
    "    merged_graph = StreamingGraph()\n",
    "    \n",
    "    for stream_graph in tqdm.tqdm(lst_graphs):\n",
    "        for day, day_graph in stream_graph.items():\n",
    "            for srs, dst_dict in day_graph.items():\n",
    "                for dst, dst_mail in dst_dict.items():\n",
    "                    merged_graph.add_pair(day, srs, dst, dst_mail.__dict__)\n",
    "                    \n",
    "    res = {key: merged_graph[key] for key in sorted(merged_graph.keys())}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parce_mail(pth):\n",
    "    mail = mailparser.parse_from_file(pth)\n",
    "    \n",
    "    d = {}\n",
    "    dt = mail.Date[:-6]\n",
    "    mask = '%a, %d %b %Y %H:%M:%S %z'\n",
    "    try:\n",
    "        d['Date'] = datetime.datetime.strptime(dt, mask)\n",
    "    except:\n",
    "        mask = '%a, %d %b %Y %H:%M:%S'\n",
    "        try:\n",
    "            d['Date'] = datetime.datetime.strptime(dt, mask)\n",
    "        except Exception as e:\n",
    "            print('ERROR')\n",
    "            print(pth)\n",
    "            print(e)\n",
    "            print('----------------------------------------------------------------')\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    d['From'] = [m.lower() for _, m in mail.From]\n",
    "    d['To'] = [m.lower() for _, m in mail.To]\n",
    "    d['CC'] = [m.lower() for _, m in mail.CC]\n",
    "    d['BCC'] = [m.lower() for _, m in mail.BCC]\n",
    "    d['Subject'] = mail.Subject.lower()\n",
    "    #d['Body'] = re.sub(r'\\s', ' ', mail.body.lower())\n",
    "    return d\n",
    "\n",
    "\n",
    "def parce_mail_dict(streaming_graph, mail_dict):\n",
    "    if mail_dict is None:\n",
    "        return\n",
    "    \n",
    "    edges_types = {'To': 2, 'CC': 3, 'BCC': 4}\n",
    "    \n",
    "    date = mail_dict['Date']\n",
    "    week = week_of_month(date)\n",
    "    # accumulate per week\n",
    "    if PERWEEK_AGGREGATION:\n",
    "        date_key = datetime.datetime(date.year, date.month, week)\n",
    "    else:\n",
    "        date_key = datetime.datetime(date.year, date.month, date.day)\n",
    "        \n",
    "    if date_key < MIN_DATE:\n",
    "        return streaming_graph\n",
    "    \n",
    "    source = mail_dict['From'][0]\n",
    "    subject = [mail_dict['Subject']]\n",
    "    \n",
    "    for dst_type in ['To', 'CC', 'BCC']:\n",
    "        for dst in mail_dict[dst_type]:\n",
    "            edge_features = {\n",
    "                'edge_weight': 1,\n",
    "                'edge_type': edges_types[dst_type],\n",
    "                'Subject': subject,\n",
    "                'isre': 'Re:' in subject\n",
    "            }\n",
    "            streaming_graph.add_pair(date_key, source, dst, edge_features)\n",
    "\n",
    "    return streaming_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_mails(streaming_graph, pth):\n",
    "    if streaming_graph is None:\n",
    "        streaming_graph = StreamingGraph()\n",
    "        \n",
    "    if osp.isdir(pth):\n",
    "        for sub_pth in listdir(pth):\n",
    "            streaming_graph = scan_mails(streaming_graph, jn(pth, sub_pth))\n",
    "        return streaming_graph\n",
    "    else:\n",
    "        streaming_graph = parce_mail_dict(streaming_graph, parce_mail(pth))\n",
    "        return streaming_graph\n",
    "        \n",
    "def scan_task(pth):\n",
    "    return scan_mails(None, pth[0])\n",
    "    \n",
    "\n",
    "def build_graph():\n",
    "    graphs = []\n",
    "    with Pool(processes=32) as p:\n",
    "        pathes = [(jn(base_path, employ), i) for i, employ in enumerate(listdir(base_path))]\n",
    "        with tqdm.tqdm(total=len(pathes)) as pbar:\n",
    "            for i, stream_graph in enumerate(p.imap_unordered(scan_task, pathes)):\n",
    "                graphs.append(stream_graph)\n",
    "                pbar.update()\n",
    "    return merge_streamin_graphs(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "STREAMING_GRAPH = build_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обход графа (не полный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for date, graph in STREAMING_GRAPH.items():\n",
    "    print(f'DATE: {date}\\n')\n",
    "    for sender, recivers_dict in graph.items():\n",
    "        print(f'    FROM: {sender}')\n",
    "        for reciver, sender_revicer_mail in recivers_dict.items():\n",
    "            print(f'        TO: {reciver}')\n",
    "            for key, val in sender_revicer_mail.items():\n",
    "                print(f'        {key}: {val}')\n",
    "            break\n",
    "        break\n",
    "    print('\\n\\n___________________________________________________________________________________\\n')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mnt/data/molchanov/datasets/pickles/{FILE_NAME}', 'wb') as f:\n",
    "    pickle.dump(STREAMING_GRAPH, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mnt/data/molchanov/datasets/pickles/{FILE_NAME}', 'rb') as f:\n",
    "    STREAMING_GRAPH = pickle.load(f)\n",
    "    STREAMING_GRAPH = {k: v for k, v in STREAMING_GRAPH.items() if count_mails(v) > 140}\n",
    "    nickn_streaming_graph(STREAMING_GRAPH)\n",
    "    \n",
    "for date, graph in STREAMING_GRAPH.items():\n",
    "    print(f'DATE: {date}\\n')\n",
    "    for sender, recivers_dict in graph.items():\n",
    "        print(f'    FROM: {sender}({MAIL2NICK[sender]})')\n",
    "        for reciver, sender_revicer_mail in recivers_dict.items():\n",
    "            print(f'        TO: {reciver}({MAIL2NICK[reciver]})')\n",
    "            for key, val in sender_revicer_mail.items():\n",
    "                print(f'        {key}: {val}')\n",
    "            break\n",
    "        break\n",
    "    print('\\n\\n___________________________________________________________________________________\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_nodes(graph):\n",
    "    nodes = set()\n",
    "    for srs, dst_dict_mails in graph.items():\n",
    "        nodes.add(srs)\n",
    "        for dst, _ in dst_dict_mails.items():\n",
    "            nodes.add(dst)\n",
    "    return nodes\n",
    "\n",
    "def get_graph_edges(graph):\n",
    "    edges = set()\n",
    "    for srs, dst_dict_mails in graph.items():\n",
    "        for dst, _ in dst_dict_mails.items():\n",
    "            edges.add(f'{srs}|{dst}')\n",
    "    return edges\n",
    "\n",
    "def filter_graph(day_key, graph, blocked_nodes):\n",
    "    filtered_graph = Graph()\n",
    "    \n",
    "    block = blocked_nodes[day_key] if isinstance(blocked_nodes, dict) else blocked_nodes\n",
    "    \n",
    "    for srs_mail, dict_dst_mails in graph.items():\n",
    "        \n",
    "        if srs_mail in block:\n",
    "            continue\n",
    "            \n",
    "        d = {k: v for k, v in dict_dst_mails.items() if k not in block}\n",
    "        if len(list(d.keys())) == 0:\n",
    "            continue\n",
    "            \n",
    "        filtered_graph[srs_mail] = d\n",
    "\n",
    "    if len(list(filtered_graph.keys())) == 0:\n",
    "        return None\n",
    "    return filtered_graph\n",
    "\n",
    "def filter_stream_graph(stream_graph, blocked_nodes):\n",
    "    g = StreamingGraph()\n",
    "    tmp = {k: filter_graph(k, v, blocked_nodes) for k, v in stream_graph.items()}\n",
    "    g.__dict__ = {k: v for k, v in tmp.items() if v is not None}\n",
    "    return g    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'grpahs count ', len(list(STREAMING_GRAPH.keys())), 'nodes count ', len(list(MAIL2NICK.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ноды spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spam_nodes(stream_graph):\n",
    "    blocked_nodes = dict()#set()\n",
    "    for date, graph in stream_graph.items():\n",
    "        senders = np.array(list(graph.keys()))\n",
    "        senders_activity = np.zeros(len(senders))\n",
    "\n",
    "        for i, sender in enumerate(senders):\n",
    "            for reciver, sender_revicer_mail in graph[sender].items():\n",
    "                senders_activity[i] += 1\n",
    "\n",
    "        max_activity = max(20, np.quantile(senders_activity, 0.95))\n",
    "        mask = senders_activity >= max_activity\n",
    "        #blocked_nodes = blocked_nodes.union(set(list(senders[mask])))\n",
    "        blocked_nodes[date] = set(list(senders[mask]))\n",
    "    return blocked_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация графа от спам нод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_nodes = get_spam_nodes(STREAMING_GRAPH)\n",
    "STREAMING_GRAPH = filter_stream_graph(STREAMING_GRAPH, spam_nodes)\n",
    "'spam_nodes count', len(spam_nodes) ,'grpahs count ', len(list(STREAMING_GRAPH.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Активность нод во времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# без учета активности внутри дня (+1/+0 если была нода активна/неактивна в течении дня, \n",
    "# не учитываем число активностей ноды внутри 1 дня)\n",
    "\n",
    "def activity_nodes_in_time(stream_graph):\n",
    "    nodes_count = len(list(MAIL2NICK.keys()))\n",
    "    nodes_activity = np.zeros(nodes_count)\n",
    "\n",
    "    for date, graph in stream_graph.items():\n",
    "        s_in = set() \n",
    "        for sender, recivers_dict in graph.items():\n",
    "            if MAIL2NICK[sender] not in s_in:\n",
    "                nodes_activity[int(MAIL2NICK[sender])] += 1\n",
    "                s_in.add(MAIL2NICK[sender])\n",
    "\n",
    "            for reciver, sender_revicer_mail in recivers_dict.items():\n",
    "                if MAIL2NICK[reciver] not in s_in:\n",
    "                    nodes_activity[int(MAIL2NICK[reciver])] += 1\n",
    "                    s_in.add(MAIL2NICK[reciver])\n",
    "\n",
    "\n",
    "    q = 0.95           \n",
    "    print(f'{q} quantile activity: {np.quantile(nodes_activity, q)}')\n",
    "    min_activity = np.quantile(nodes_activity, q)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.title(['Активность нод без учета активности внутри дня'])\n",
    "    plt.scatter(np.arange(nodes_activity.shape[0]), np.sort(nodes_activity), color='red')\n",
    "    plt.plot(np.arange(nodes_activity.shape[0]), [min_activity] * nodes_activity.shape[0], color='black')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    low_activiti_nodes = np.arange(nodes_count)\n",
    "    mask = nodes_activity < min_activity\n",
    "    low_activiti_nodes = low_activiti_nodes[mask]\n",
    "    \n",
    "    return set([NICK2MAIL[str(node)] for node in low_activiti_nodes])\n",
    "\n",
    "low_activity_nodes = activity_nodes_in_time(STREAMING_GRAPH)\n",
    "'low activity nodes count', len(low_activity_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREAMING_GRAPH = filter_stream_graph(STREAMING_GRAPH, low_activity_nodes)\n",
    "'spam_nodes count', len(spam_nodes) ,'grpahs count ', len(list(STREAMING_GRAPH.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU общих нод между двумя последовательными графами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_nodes(graph):\n",
    "    nodes = set()\n",
    "    for srs_mail, dict_dst_mails in graph.items():\n",
    "        nodes.add(MAIL2NICK[srs_mail])\n",
    "        for dst_mail, mail_info in dict_dst_mails.items():\n",
    "            nodes.add(MAIL2NICK[dst_mail])\n",
    "    return nodes\n",
    "\n",
    "def successive_ious():\n",
    "    ious = []\n",
    "    for i in range(1, len(list(STREAMING_GRAPH.keys()))):\n",
    "        day_key1, day_key2 = list(STREAMING_GRAPH.keys())[i - 1], list(STREAMING_GRAPH.keys())[i]\n",
    "        graph1, graph2 = STREAMING_GRAPH[day_key1], STREAMING_GRAPH[day_key2]\n",
    "        nodes1, nodes2 = get_graph_nodes(graph1), get_graph_nodes(graph2)\n",
    "\n",
    "        intersec = len(nodes1.intersection(nodes2))\n",
    "        union = len(nodes1.union(nodes2))\n",
    "\n",
    "        iou = float(intersec)/union\n",
    "        ious.append(iou)\n",
    "    \n",
    "    print(f'IOUS mean: {np.array(ious).mean()}, std: {np.array(ious).std()}')\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.title(['IOU общих нод между двумя последовательными графами'])\n",
    "    plt.plot(np.arange(len(ious)), ious, color='red')\n",
    "    \n",
    "successive_ious()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_day_graph(day):\n",
    "    day_key = list(STREAMING_GRAPH.keys())[day]\n",
    "    day_graph = STREAMING_GRAPH[day_key]\n",
    "    \n",
    "    edges = []\n",
    "    for srs_mail, dict_dst_mails in day_graph.items():\n",
    "        for dst_mail, mail_info in dict_dst_mails.items():\n",
    "            edges.append((MAIL2NICK[srs_mail], MAIL2NICK[dst_mail]))\n",
    "            \n",
    "    mails_count = count_mails(day_graph)\n",
    "            \n",
    "    print(f'day {day_key} num edges = {len(edges)}')\n",
    "    \n",
    "    \n",
    "    G=nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    #print(f'nodes: {G.nodes()}')\n",
    "    \n",
    "    nx.draw(G, with_labels=True)\n",
    "    plt.figure(figsize=(80,80))\n",
    "    #plt.savefig(f\"{day_key.year}_{day_key.month}_{day_key.day}.png\") # save as png\n",
    "    plt.show() # display\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(len(list(STREAMING_GRAPH.keys()))):\n",
    "    draw_day_graph(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
