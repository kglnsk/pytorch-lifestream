{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_AUGMENTS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.7\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "SAMPLING_STRATEGY = 'HardNegativePair'\n",
    "NEGATIVES_COUNT = N_AUGMENTS + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2Normalization, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.div(torch.norm(input, dim=1).view(-1, 1))\n",
    "    \n",
    "    \n",
    "def outer_pairwise_distance(A, B=None):\n",
    "    \"\"\"\n",
    "        Compute pairwise_distance of Tensors\n",
    "            A (size(A) = n x d, where n - rows count, d - vector size) and\n",
    "            B (size(A) = m x d, where m - rows count, d - vector size)\n",
    "        return matrix C (size n x m), such as C_ij = distance(i-th row matrix A, j-th row matrix B)\n",
    "\n",
    "        if only one Tensor was given, computer pairwise distance to itself (B = A)\n",
    "    \"\"\"\n",
    "\n",
    "    if B is None: B = A\n",
    "\n",
    "    max_size = 2 ** 26\n",
    "    n = A.size(0)\n",
    "    m = B.size(0)\n",
    "    d = A.size(1)\n",
    "\n",
    "    if n * m * d <= max_size or m == 1:\n",
    "\n",
    "        return torch.pairwise_distance(\n",
    "            A[:, None].expand(n, m, d).reshape((-1, d)),\n",
    "            B.expand(n, m, d).reshape((-1, d))\n",
    "        ).reshape((n, m))\n",
    "\n",
    "    else:\n",
    "\n",
    "        batch_size = max(1, max_size // (n * d))\n",
    "        batch_results = []\n",
    "        for i in range((m - 1) // batch_size + 1):\n",
    "            id_left = i * batch_size\n",
    "            id_rigth = min((i + 1) * batch_size, m)\n",
    "            batch_results.append(outer_pairwise_distance(A, B[id_left:id_rigth]))\n",
    "\n",
    "        return torch.cat(batch_results, dim=1)\n",
    "    \n",
    "def outer_cosine_similarity(A, B=None):\n",
    "    \"\"\"\n",
    "        Compute cosine_similarity of Tensors\n",
    "            A (size(A) = n x d, where n - rows count, d - vector size) and\n",
    "            B (size(A) = m x d, where m - rows count, d - vector size)\n",
    "        return matrix C (size n x m), such as C_ij = cosine_similarity(i-th row matrix A, j-th row matrix B)\n",
    "\n",
    "        if only one Tensor was given, computer pairwise distance to itself (B = A)\n",
    "    \"\"\"\n",
    "\n",
    "    if B is None: B = A\n",
    "\n",
    "    max_size = 2 ** 32\n",
    "    n = A.size(0)\n",
    "    m = B.size(0)\n",
    "    d = A.size(1)\n",
    "\n",
    "    if n * m * d <= max_size or m == 1:\n",
    "\n",
    "        A_norm = torch.div(A.transpose(0, 1), A.norm(dim=1)).transpose(0, 1)\n",
    "        B_norm = torch.div(B.transpose(0, 1), B.norm(dim=1)).transpose(0, 1)\n",
    "        return torch.mm(A_norm, B_norm.transpose(0, 1))\n",
    "\n",
    "    else:\n",
    "\n",
    "        batch_size = max(1, max_size // (n * d))\n",
    "        batch_results = []\n",
    "        for i in range((m - 1) // batch_size + 1):\n",
    "            id_left = i * batch_size\n",
    "            id_rigth = min((i + 1) * batch_size, m)\n",
    "            batch_results.append(outer_cosine_similarity(A, B[id_left:id_rigth]))\n",
    "\n",
    "        return torch.cat(batch_results, dim=1)\n",
    "    \n",
    "def metric_Recall_top_K(X, y, K, metric='cosine'):\n",
    "    \"\"\"\n",
    "        calculate metric R@K\n",
    "        X - tensor with size n x d, where n - number of examples, d - size of embedding vectors\n",
    "        y - true labels\n",
    "        N - count of closest examples, which we consider for recall calcualtion\n",
    "        metric: 'cosine' / 'euclidean'.\n",
    "            !!! 'euclidean' - to slow for datasets bigger than 100K rows\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    n = X.size(0)\n",
    "    d = X.size(1)\n",
    "    max_size = 2 ** 32\n",
    "    batch_size = max(1, max_size // (n*d))\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range(1 + (len(X) - 1) // batch_size):\n",
    "\n",
    "            id_left = i*batch_size\n",
    "            id_right = min((i+1)*batch_size, len(y))\n",
    "            y_batch = y[id_left:id_right]\n",
    "\n",
    "            if metric == 'cosine':\n",
    "                pdist = -1 * outer_cosine_similarity(X, X[id_left:id_right])\n",
    "            elif metric == 'euclidean':\n",
    "                pdist = outer_pairwise_distance(X, X[id_left:id_right])\n",
    "            else:\n",
    "                raise AttributeError(f'wrong metric \"{metric}\"')\n",
    "\n",
    "            values, indices = pdist.topk(K + 1, 0, largest=False)\n",
    "\n",
    "            y_rep = y_batch.repeat(K, 1)\n",
    "            res.append((y[indices[1:]] == y_rep).sum().item())\n",
    "\n",
    "    return np.sum(res) / len(y) / K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairSelector:\n",
    "    \"\"\"\n",
    "    Implementation should return indices of positive pairs and negative pairs that will be passed to compute\n",
    "    Contrastive Loss\n",
    "    return positive_pairs, negative_pairs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_pairs(self, embeddings, labels):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class HardNegativePairSelector(PairSelector):\n",
    "    \"\"\"\n",
    "    Generates all possible possitive pairs given labels and\n",
    "         neg_count hardest negative example for each example\n",
    "    \"\"\"\n",
    "    def __init__(self, neg_count = 1):\n",
    "        super(HardNegativePairSelector, self).__init__()\n",
    "        self.neg_count = neg_count\n",
    "\n",
    "    def get_pairs(self, embeddings, labels):\n",
    "        \n",
    "        # construct matrix x, such as x_ij == 0 <==> labels[i] == labels[j]\n",
    "        n = labels.size(0)\n",
    "        x = labels.expand(n,n) - labels.expand(n,n).t()        \n",
    "            \n",
    "        # positive pairs\n",
    "        positive_pairs = torch.triu((x == 0).int(), diagonal = 1).nonzero()\n",
    "        \n",
    "        # hard negative minning\n",
    "        mat_distances = outer_pairwise_distance(embeddings.detach()) # pairwise_distance\n",
    "        \n",
    "        upper_bound = int((2*n) ** 0.5) + 1\n",
    "        mat_distances = ((upper_bound - mat_distances) * (x != 0).type(mat_distances.dtype)) # filter: get only negative pairs\n",
    "        \n",
    "        values, indices = mat_distances.topk(k = self.neg_count, dim = 0, largest = True)\n",
    "        negative_pairs = torch.stack([\n",
    "            torch.arange(0,n, dtype = indices.dtype, device = indices.device).repeat(self.neg_count),\n",
    "            torch.cat(indices.unbind(dim = 0))\n",
    "        ]).t()\n",
    "\n",
    "        return positive_pairs, negative_pairs\n",
    "        \n",
    "def get_sampling_strategy(params='HardNegativePair'):\n",
    "    if params == 'HardNegativePair':\n",
    "        kwargs = {\n",
    "            'neg_count' : NEGATIVES_COUNT,\n",
    "        }\n",
    "        kwargs = {k:v for k,v in kwargs.items() if v is not None}\n",
    "        sampling_strategy = HardNegativePairSelector(**kwargs)\n",
    "        return sampling_strategy\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS/MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_train_dataset = torchvision.datasets.MNIST('/mnt/data/molchanov/datasets/mnist', \n",
    "                                           train=True, \n",
    "                                           transform=None, \n",
    "                                           target_transform=None, \n",
    "                                           download=True)\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('/mnt/data/molchanov/datasets/mnist', \n",
    "                                           train=False, \n",
    "                                           transform=None, \n",
    "                                           target_transform=None, \n",
    "                                           download=True)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# very slow\n",
    "def mnist_augmentation(p=1):\n",
    "    return Compose([\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=1),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.33),\n",
    "            MedianBlur(blur_limit=3, p=0.33),\n",
    "            Blur(blur_limit=3, p=0.33),\n",
    "        ], p=1),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.33),\n",
    "            GridDistortion(p=0.33),\n",
    "            IAAPiecewiseAffine(p=0.33)\n",
    "        ], p=1),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=1),\n",
    "    ], p=p)\n",
    "\n",
    "\n",
    "def mnist_torch_augmentation(p=1):\n",
    "    return torchvision.transforms.Compose([\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomAffine(degrees=7, \n",
    "                                translate=(0.1, 0.1), \n",
    "                                scale=(0.9, 0.9), \n",
    "                                shear=None, \n",
    "                                resample=False, \n",
    "                                fillcolor=0),\n",
    "            transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)\n",
    "        ]),\n",
    "        transforms.ColorJitter(brightness=0.7, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "    ])\n",
    "plt.imshow(mnist_test_dataset[0][0])\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "class MnistClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.norm = L2Normalization()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) == 4:\n",
    "            x = x[:, -1, :, :].unsqueeze(1) # get augmented image\n",
    "        else:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.norm(x)\n",
    "        return output\n",
    "    \n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "class MnistMetricLearningNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 256)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, x.size(-2), x.size(-1)) # b, augs, x, y -> b*augs, 1, x, y\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55d79d5fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar10_train_dataset = torchvision.datasets.CIFAR10('/mnt/data/molchanov/datasets/cifar10', \n",
    "                                               train=True, \n",
    "                                               transform=None, \n",
    "                                               target_transform=None, \n",
    "                                               download=True)\n",
    "\n",
    "cifar10_test_dataset = torchvision.datasets.CIFAR10('/mnt/data/molchanov/datasets/cifar10', \n",
    "                                               train=False, \n",
    "                                               transform=None, \n",
    "                                               target_transform=None, \n",
    "                                               download=True)\n",
    "\n",
    "plt.imshow(cifar10_test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55d7a59a50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar100_train_dataset = torchvision.datasets.CIFAR100('/mnt/data/molchanov/datasets/cifar100', \n",
    "                                               train=True, \n",
    "                                               transform=None, \n",
    "                                               target_transform=None, \n",
    "                                               download=True)\n",
    "\n",
    "cifar100_test_dataset = torchvision.datasets.CIFAR100('/mnt/data/molchanov/datasets/cifar100', \n",
    "                                               train=False, \n",
    "                                               transform=None, \n",
    "                                               target_transform=None, \n",
    "                                               download=True)\n",
    "\n",
    "plt.imshow(cifar100_test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation Dataset/Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetrLearnDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, augmenter, n_augments=10):\n",
    "        self.data = dataset\n",
    "        self.aug = augmenter\n",
    "        self.n_augments = n_augments\n",
    "        \n",
    "    def draw(self, idx):\n",
    "        imgs, lbl = self[idx]\n",
    "        print(imgs.shape, lbl)\n",
    "        fig = plt.figure()\n",
    "        rows, columns = 1, imgs.shape[0]\n",
    "        for i in range(imgs.shape[0]):\n",
    "            fig.add_subplot(rows, columns, i+1)\n",
    "            plt.imshow(imgs[i])\n",
    "        plt.show()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    '''\n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx]\n",
    "        imgs = [np.array(img)] + [self.aug(image=np.array(img))['image'] for i in range(self.n_augments)]\n",
    "        b_img = np.stack(imgs, axis=0)\n",
    "        return b_img, lbl\n",
    "    '''\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx]\n",
    "        imgs = [transforms.ToTensor()(img)] + [self.aug(img) for i in range(self.n_augments)]\n",
    "        b_img = torch.stack(imgs).squeeze()\n",
    "        return b_img, lbl\n",
    "        \n",
    "    \n",
    "def get_mnist_train_loader(batch_size, n_augments=4):\n",
    "    data_train = MetrLearnDataset(dataset=mnist_train_dataset, \n",
    "                            augmenter=mnist_torch_augmentation(p=1), \n",
    "                            n_augments=n_augments)\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=16)\n",
    "    return train_data_loader\n",
    "    \n",
    "def get_mnist_test_loader(batch_size, n_augments=4):\n",
    "    data_test = MetrLearnDataset(dataset=mnist_test_dataset, \n",
    "                            augmenter=mnist_torch_augmentation(p=1), \n",
    "                            n_augments=n_augments)\n",
    "        \n",
    "    test_data_loader = torch.utils.data.DataLoader(data_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=5)\n",
    "    return test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 28, 28]) 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 529 ms, sys: 0 ns, total: 529 ms\n",
      "Wall time: 526 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = MetrLearnDataset(dataset=mnist_test_dataset, \n",
    "                        augmenter=mnist_torch_augmentation(p=1), \n",
    "                        n_augments=N_AUGMENTS)\n",
    "data.draw(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss\n",
    "    \n",
    "    \"Signature verification using a siamese time delay neural network\", NIPS 1993\n",
    "    https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, pair_selector):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pair_selector = pair_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "        \n",
    "        positive_pairs, negative_pairs = self.pair_selector.get_pairs(embeddings, target)\n",
    "        positive_loss = F.pairwise_distance(embeddings[positive_pairs[:, 0]], embeddings[positive_pairs[:, 1]]).pow(2)\n",
    "        \n",
    "        negative_loss = F.relu(\n",
    "            self.margin - F.pairwise_distance(embeddings[negative_pairs[:, 0]], embeddings[negative_pairs[:, 1]])\n",
    "        ).pow(2)\n",
    "        loss = torch.cat([positive_loss, negative_loss], dim=0)\n",
    "        \n",
    "        return loss.sum(), len(positive_pairs) + len(negative_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaunchInfo:\n",
    "    \n",
    "    def __init__(self, model, loss, optimizer, scheduler, train_loader, test_loader, epochs, device, mode):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.epochs = epochs\n",
    "        self.mode = mode\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            self.scheduler = scheduler\n",
    "        else:\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer,\n",
    "                                                             step_size=1,\n",
    "                                                             gamma=GAMMA)\n",
    "            \n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            \n",
    "        self.model.to(device)\n",
    "        self.loss.to(device)\n",
    "        \n",
    "# -------------------------- predefind configs --------------------------------\n",
    "        \n",
    "mnist_classification_lunch_info = LaunchInfo(model=MnistClassificationNet(), \n",
    "                                             loss=torch.nn.NLLLoss(), \n",
    "                                             optimizer=None, \n",
    "                                             scheduler=None, \n",
    "                                             train_loader=get_mnist_train_loader(batch_size=BATCH_SIZE, \n",
    "                                                                                 n_augments=N_AUGMENTS), \n",
    "                                             test_loader=get_mnist_test_loader(batch_size=BATCH_SIZE, \n",
    "                                                                               n_augments=N_AUGMENTS), \n",
    "                                             epochs=EPOCHS, \n",
    "                                             device='cuda',\n",
    "                                             mode='classification')\n",
    "    \n",
    "mnist_metriclearning_lunch_info = LaunchInfo(model=MnistMetricLearningNet(), \n",
    "                                             loss=ContrastiveLoss(margin=0.1, \n",
    "                                                                  pair_selector=get_sampling_strategy(SAMPLING_STRATEGY)), \n",
    "                                             optimizer=None, \n",
    "                                             scheduler=None, \n",
    "                                             train_loader=get_mnist_train_loader(batch_size=BATCH_SIZE, \n",
    "                                                                                 n_augments=N_AUGMENTS), \n",
    "                                             test_loader=get_mnist_test_loader(batch_size=BATCH_SIZE, \n",
    "                                                                               n_augments=N_AUGMENTS), \n",
    "                                             epochs=EPOCHS, \n",
    "                                             device='cuda',\n",
    "                                             mode='metric_learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    \n",
    "    def __init__(self, launch_info):\n",
    "        self.info = launch_info\n",
    "        \n",
    "        self.model = self.info.model\n",
    "        self.loss = self.info.loss\n",
    "        self.optimizer = self.info.optimizer\n",
    "        self.scheduler = self.info.scheduler\n",
    "        self.epochs = self.info.epochs\n",
    "        self.train_loader = self.info.train_loader\n",
    "        self.test_loader = self.info.test_loader\n",
    "        self.device = self.info.device\n",
    "        self.mode = self.info.mode\n",
    "        \n",
    "        \n",
    "    def train_epoch(self, step):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        with tqdm.notebook.tqdm(total=len(self.train_loader)) as steps:\n",
    "            for itr, data in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                device_data = self.data_to_device(data)\n",
    "                labels = device_data[1]\n",
    "                \n",
    "                out = self.model(device_data[0])\n",
    "                if self.mode == 'metric_learning':\n",
    "                    labels = torch.arange(int(out.size(0)/(N_AUGMENTS + 1))).view(1, -1).repeat(N_AUGMENTS+1, 1).transpose(0, 1).flatten().to(self.device)\n",
    "                \n",
    "                loss = self.loss(out, labels)\n",
    "                if self.mode == 'metric_learning':\n",
    "                    loss, pos_neg_len = loss[0], loss[1]\n",
    "                losses.append(loss.item())\n",
    "                loss_val = self.running_average(losses)\n",
    "                loss.backward()\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                steps.set_description(f\"train: epoch {step}, step {itr}/{len(self.train_loader)}\")\n",
    "                if self.mode == 'classification':\n",
    "                    steps.set_postfix({\"loss\": '{:.5E}'.format(loss_val)})\n",
    "                elif self.mode == 'metric_learning':\n",
    "                    steps.set_postfix({\"loss\": '{:.5E}'.format(loss_val),\n",
    "                                       \"pos_neg_len\": pos_neg_len})\n",
    "                steps.update()\n",
    "        \n",
    "    def test_epoch(self, step):\n",
    "        self.model.eval()\n",
    "        losses, total, corrects = [], 0, 0\n",
    "        total_recall = 0\n",
    "        with torch.no_grad():\n",
    "            with tqdm.notebook.tqdm(total=len(self.test_loader)) as steps:\n",
    "                for itr, data in enumerate(self.test_loader):\n",
    "                    device_data = self.data_to_device(data)\n",
    "                    labels = device_data[1]\n",
    "                    \n",
    "                    out = self.model(device_data[0])\n",
    "                    if self.mode == 'metric_learning':\n",
    "                        labels = torch.arange(int(out.size(0)/(N_AUGMENTS + 1))).view(1, -1).repeat(N_AUGMENTS+1, 1).transpose(0, 1).flatten().to(self.device)\n",
    "                \n",
    "                    loss = self.loss(out, labels)\n",
    "                    if self.mode == 'metric_learning':\n",
    "                        loss, pos_neg_len = loss[0], loss[1]\n",
    "                    losses.append(loss.item())\n",
    "                    loss_val = self.running_average(losses)\n",
    "                    \n",
    "                    if self.mode == 'classification':\n",
    "                        pred = F.softmax(out, dim=-1).argmax(dim=-1)\n",
    "                        corrects += pred.eq(device_data[1].view_as(pred)).sum().item()\n",
    "                        total += pred.size(0)\n",
    "                        accuracy = corrects/total\n",
    "                    elif self.mode == 'metric_learning':\n",
    "                        batch_recall = metric_Recall_top_K(out, labels, N_AUGMENTS)\n",
    "                        total_recall += batch_recall\n",
    "                    \n",
    "                    steps.set_description(f\"test: epoch {step}, step {itr}/{len(self.train_loader)}\")\n",
    "                    if self.mode == 'classification':\n",
    "                        steps.set_postfix({\"loss\": '{:.5E}'.format(loss_val), \"accuracy\": accuracy})\n",
    "                    elif self.mode == 'metric_learning':\n",
    "                        steps.set_postfix({\"loss\": '{:.5E}'.format(loss_val),\n",
    "                                           \"batch_recall\": batch_recall,\n",
    "                                           \"recal_recall\": total_recall/(itr+1)})\n",
    "                    steps.update()\n",
    "        \n",
    "    def fit(self):\n",
    "        for step in range(self.epochs):\n",
    "            self.train_epoch(step + 1)\n",
    "            self.test_epoch(step + 1)\n",
    "            self.scheduler.step()\n",
    "            \n",
    "    def data_to_device(self, data):\n",
    "        return data[0].to(self.device).float(), data[1].to(self.device)\n",
    "    \n",
    "    def running_average(self, x):\n",
    "        arr = np.array(x)[-1000:]\n",
    "        res = np.convolve(arr, np.ones((arr.shape[0],)))/arr.shape[0]\n",
    "        return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mnist_classification_learner = Learner(launch_info=mnist_classification_lunch_info)\n",
    "mnist_classification_learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5073de3357e74a2a85fccba7e89f1091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b8e0d1b8864b60af54807594ddfed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0fd7de4448443f991174ff00d62da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd0160124ae4d3f837bb57114f969ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac18f2cc0da449fb75253325f9d03a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3333c0929b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmnist_metriclearning_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaunch_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_metriclearning_lunch_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist_metriclearning_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-173bab7eb067>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-173bab7eb067>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_AUGMENTS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_AUGMENTS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'metric_learning'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_neg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f4100852b0f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, target)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpositive_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpair_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpositive_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositive_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositive_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d9c2e92c177b>\u001b[0m in \u001b[0;36mget_pairs\u001b[0;34m(self, embeddings, labels)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_distances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         negative_pairs = torch.stack([\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         ]).t()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnist_metriclearning_learner = Learner(launch_info=mnist_metriclearning_lunch_info)\n",
    "mnist_metriclearning_learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
