{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekko challenge 2019\n",
    "\n",
    "```\n",
    "                           /$$$$$$$  /$$$$$$$$ /$$   /$$ /$$   /$$  /$$$$$$ \n",
    "                          | $$__  $$| $$_____/| $$  /$$/| $$  /$$/ /$$__  $$\n",
    "                          | $$  \\ $$| $$      | $$ /$$/ | $$ /$$/ | $$  \\ $$\n",
    "                          | $$$$$$$/| $$$$$   | $$$$$/  | $$$$$/  | $$  | $$\n",
    "                          | $$__  $$| $$__/   | $$  $$  | $$  $$  | $$  | $$\n",
    "                          | $$  \\ $$| $$      | $$\\  $$ | $$\\  $$ | $$  | $$\n",
    "                          | $$  | $$| $$$$$$$$| $$ \\  $$| $$ \\  $$|  $$$$$$/\n",
    "                          |__/  |__/|________/|__/  \\__/|__/  \\__/ \\______/ \n",
    "                                                                            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добро пожаловать на соревнование по машинному обучению от онлайн-кинотеатра [Okko](http://okko.tv) Rekko Challenge 2019.\n",
    "\n",
    "В этом ноутбуке мы покажем вам пример простого но полного решения, от загрузки данных до формирования ответа. Для работы нам понадобятся библиотеки `pandas`, `numpy`, `scipy`, `implicit`, `pprint`, `tqdm`. Установить их в вашем рабочем окружении можно следующей командой.\n",
    "```\n",
    "pip install pandas numpy scipy implicit pprint tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замените `DATA_PATH` на путь к данным, которые вы скачали со страницы соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt/data/molchanov/datasets/okko/rekko_challenge_rekko_challenge_2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`catalogue.json` содержит анонимизированную метаинформацию о доступных в сервисе фильмах и сериалах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'catalogue.json'), 'r') as f:\n",
    "    catalogue = json.load(f)\n",
    "    \n",
    "catalogue = {int(k): v for k, v in catalogue.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(catalogue[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue2 = defaultdict(list)\n",
    "for key, val in catalogue.items():\n",
    "    if 'purchase' in val['availability']:\n",
    "        catalogue2['purchase'].append(1)\n",
    "    else:\n",
    "        catalogue2['purchase'].append(0)\n",
    "        \n",
    "    if 'rent' in val['availability']:\n",
    "        catalogue2['rent'].append(1)\n",
    "    else:\n",
    "        catalogue2['rent'].append(0)\n",
    "        \n",
    "    if 'subscription' in val['availability']:\n",
    "        catalogue2['subscription'].append(1)\n",
    "    else:\n",
    "        catalogue2['subscription'].append(0)\n",
    "        \n",
    "    catalogue2['element_uid'].append(key)\n",
    "    catalogue2['feature_1'].append(val['feature_1'])\n",
    "    catalogue2['feature_2'].append(val['feature_2'])\n",
    "    catalogue2['feature_3'].append(val['feature_3'])\n",
    "    catalogue2['feature_4'].append(val['feature_4'])\n",
    "    catalogue2['feature_5'].append(val['feature_5'])\n",
    "    catalogue2['duration'].append(val['duration'])\n",
    "    catalogue2['type'].append(val['type'])\n",
    "\n",
    "df_catalogue = pd.DataFrame({\n",
    "    'element_uid': catalogue2['element_uid'],\n",
    "    \n",
    "    'feature_1': catalogue2['feature_1'],\n",
    "    'feature_2': catalogue2['feature_2'],\n",
    "    'feature_3': catalogue2['feature_3'],\n",
    "    'feature_4': catalogue2['feature_4'],\n",
    "    'feature_5': catalogue2['feature_5'],\n",
    "    \n",
    "    'type': catalogue2['type'],\n",
    "    'duration': catalogue2['duration'],\n",
    "    \n",
    "    'purchase': catalogue2['purchase'],\n",
    "    'rent': catalogue2['rent'],\n",
    "    'subscription': catalogue2['subscription'],\n",
    "})\n",
    "\n",
    "df_catalogue['feature_1'] = df_catalogue['feature_1'].astype(np.float64)\n",
    "df_catalogue['feature_2'] = df_catalogue['feature_2'].astype(np.float64)\n",
    "df_catalogue['feature_3'] = df_catalogue['feature_3'].astype('category').cat.codes\n",
    "df_catalogue['feature_4'] = df_catalogue['feature_4'].astype(np.float64)\n",
    "df_catalogue['feature_5'] = df_catalogue['feature_5'].astype(np.float64)\n",
    "df_catalogue['element_uid'] = df_catalogue['element_uid'].astype(np.uint16)\n",
    "df_catalogue['duration'] = df_catalogue['duration'].astype(np.uint64)\n",
    "df_catalogue['type'] = df_catalogue['type'].astype('category').cat.codes\n",
    "df_catalogue.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `attributes` — мешок атрибутов\n",
    " - `availability` — доступность (может содержать значения `purchase`, `rent` и `subscription`)\n",
    " - `duration` — длительность в минутах, округлённая до десятков (продолжительность серии для сериалов и многосерийных фильмов)\n",
    " - `feature_1..5` — пять анонимизированных вещественных и порядковых признаков\n",
    " - `type` — принимает значения `movie`, `multipart_movie` или `series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalogue['element_uid'].values.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_users.json` содержит список пользователей, для которых необходимо построить предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'test_users.json'), 'r') as f:\n",
    "    test_users = set(json.load(f)['users'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transactions.csv` — список всех транзакций за определённый период времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transactions = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'transactions.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'consumption_mode': 'category',\n",
    "        'ts': np.float64,\n",
    "        'watched_time': np.uint64,\n",
    "        'device_type': np.uint8,\n",
    "        'device_manufacturer': np.uint8\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['device_manufacturer'].values.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `element_uid` — идентификатор элемента\n",
    " - `user_uid` — идентификатор пользователя\n",
    " - `consumption_mode` — тип потребления (`P` — покупка, `R` — аренда, `S` — просмотр по подписке)\n",
    " - `ts` — время совершения транзакции или начала просмотра в случае просмотра по подписке\n",
    " - `watched_time` — число просмотренных по транзакции секунд\n",
    " - `device_type` — анонимизированный тип устройства, с которого была совершена транзакция или начат просмотр\n",
    " - `device_manufacturer` — анонимизированный производитель устройства, с которого была совершена транзакция или начат просмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = None\n",
    "\n",
    "transactions_ex = pd.merge(transactions, df_catalogue, on='element_uid', how='left')\n",
    "\n",
    "columns = ['element_uid', \n",
    "           'consumption_mode', \n",
    "           'device_type', \n",
    "           'device_manufacturer', \n",
    "           'watched_time',\n",
    "           'feature_1',\n",
    "           'feature_2',\n",
    "           'feature_3',\n",
    "           'feature_4',\n",
    "           'feature_5',\n",
    "           'type',\n",
    "           'duration',\n",
    "           'purchase',\n",
    "           'rent',\n",
    "           'subscription'\n",
    "          ]\n",
    "main_col = 'user_uid'\n",
    "\n",
    "transactions_ex['consumption_mode'] = transactions_ex['consumption_mode'].astype('category').cat.codes\n",
    "\n",
    "for group_col in tqdm.tqdm(columns):\n",
    "    tmp = transactions_ex.sort_values([main_col,'ts'],ascending=False).\\\n",
    "                                    groupby(['user_uid'])[group_col].\\\n",
    "                                    apply(list).\\\n",
    "                                    reset_index()\n",
    "    if dataset is None:\n",
    "        dataset = tmp\n",
    "    else:\n",
    "        dataset = pd.merge(dataset, tmp, on=main_col)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(os.path.join(DATA_PATH, 'transactions_grouped.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(DATA_PATH, 'transactions_grouped.csv'))\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "columns = ['element_uid', 'consumption_mode',\n",
    "       'device_type', 'device_manufacturer', 'watched_time', 'feature_1',\n",
    "       'feature_2', 'feature_3', 'feature_4', 'feature_5', 'type', 'duration',\n",
    "       'purchase', 'rent', 'subscription']\n",
    "\n",
    "pickle_dataset = []\n",
    "for index, row in dataset.iterrows():\n",
    "    feature_arrays = dict()\n",
    "    for col in columns:\n",
    "        feature_arrays[col] =  ast.literal_eval(row[col])\n",
    "        \n",
    "    itm = dict()\n",
    "    itm['user_uid'] = row['user_uid']\n",
    "    itm['len'] = len(feature_arrays['element_uid'])\n",
    "    itm['feature_arrays'] = feature_arrays\n",
    "    \n",
    "    pickle_dataset.append(itm)\n",
    "    \n",
    "pickle_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in pickle_dataset:\n",
    "    if 'type' in val['feature_arrays']:\n",
    "        val['feature_arrays']['video_type'] = val['feature_arrays']['type']\n",
    "        val['feature_arrays'].pop('type', None)\n",
    "pickle_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'transactions_grouped.pkl'), 'wb') as f:\n",
    "    pickle.dump(pickle_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'transactions_grouped.pkl'), 'rb') as f:\n",
    "    pickle_dataset = pickle.load(f)\n",
    "pickle_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens histogram\n",
    "import matplotlib.pyplot as plt\n",
    "l = []\n",
    "for v in pickle_dataset:\n",
    "    if v['len'] > 200:\n",
    "        continue\n",
    "    l.append(v['len'])\n",
    "    \n",
    "plt.hist(l, bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(100)]\n",
    "np.random.randint(0, 2, (100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ratings.csv` содержит информацию о поставленных пользователями оценках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'ratings.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64,\n",
    "        'rating': np.uint8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `rating` — поставленный пользователем рейтинг (от `0` до `10`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bookmarks.csv` содержит информацию об элементах, добавленных пользователями в список «Избранное»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bookmarks = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'bookmarks.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmarks.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала построим список элементов, которые тестовые пользователи уже купили или посмотрели по подписке: они не смогут купить их второй раз, а просмотр по подписке второй раз маловероятен, поэтому мы захотим отфильтровать такие элементы из финального ответа.\n",
    "\n",
    "Точно так же можно поступить и с рейтингами и добавлениями в избранное, если это будет казаться правильным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "filtered_elements = defaultdict(set)\n",
    "\n",
    "for user_uid, element_uid in tqdm.tqdm(transactions.loc[:, ['user_uid', 'element_uid']].values):\n",
    "    if user_uid not in test_users:\n",
    "        continue\n",
    "    filtered_elements[user_uid].add(element_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера мы воспользуемся методом K ближайших соседей, реализованным в библиотеке `implicit`. В качестве данных используем только информацию о рейтингах.\n",
    "\n",
    "Необходимо построить разреженную матрицу, где строкам будут соответствовать элементы, столбцам — пользователи, а на пересечении пользователя и элемента будет находиться количественная оценка степени их взаимодействия, если таковое имело место.\n",
    "\n",
    "Не забудем добавить `1` к рейтингу, чтобы избежать деления на ноль во время вычисления `tf-idf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['user_uid'] = ratings['user_uid'].astype('category')\n",
    "ratings['element_uid'] = ratings['element_uid'].astype('category')\n",
    "\n",
    "ratings_matrix = sp.coo_matrix(\n",
    "    (ratings['rating'].astype(np.float32) + 1,\n",
    "        (\n",
    "            ratings['element_uid'].cat.codes.copy(),\n",
    "            ratings['user_uid'].cat.codes.copy()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ratings_matrix = ratings_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = ratings_matrix.nnz / (ratings_matrix.shape[0] * ratings_matrix.shape[1])\n",
    "print('Sparsity: %.6f' % sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить модель крайне просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import TFIDFRecommender\n",
    "\n",
    "model = TFIDFRecommender()\n",
    "model.fit(ratings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_T = ratings_matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отображения из оригинальной категории во внутреннюю пригодится нам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_uid_to_cat = dict(zip(\n",
    "    ratings['user_uid'].cat.categories,\n",
    "    range(len(ratings['user_uid'].cat.categories))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_uid_to_cat = dict(zip(\n",
    "    ratings['element_uid'].cat.categories,\n",
    "    range(len(ratings['element_uid'].cat.categories))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_elements_cat = {k: [element_uid_to_cat.get(x, None) for x in v] for k, v in filtered_elements.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метод `model.recommend` мы передаём идентификатор пользователя, который получаем обратным преобразованием из категории, транспонированную матрицу взаимодействий, число необходимых рекомендаций и список элементов, которые мы договорились фильтровать из ответа.\n",
    "\n",
    "Возвращает метод список пар (`element_cat`, `score`), отсортированный по вторым элементам. Из него необходимо достать все первые элементы пар и из категории преобразовать их к `element_uid`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно:** Не все тестовые пользователи есть в `ratings.csv` и не все из них есть в `transactions.csv`. Используя только один источник данных мы не можем построить полное предсказание. Такой ответ с неполным числом пользователей бдет принят системой, но при вычислении средней метрики метрика для отсутствующих пользователей будет принята равной нулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for user_uid in tqdm.tqdm(test_users):\n",
    "    # transform user_uid to model's internal user category\n",
    "    try:\n",
    "        user_cat = user_uid_to_cat[user_uid]\n",
    "    except LookupError:\n",
    "        continue\n",
    "    \n",
    "    # perform inference\n",
    "    recs = model.recommend(\n",
    "        user_cat,\n",
    "        ratings_matrix_T,\n",
    "        N=20,\n",
    "        filter_already_liked_items=True,\n",
    "        filter_items=filtered_elements_cat.get(user_uid, set())\n",
    "    )\n",
    "    \n",
    "    # drop scores and transform model's internal elelemnt category to element_uid for every prediction\n",
    "    # also convert np.uint64 to int so it could be json serialized later\n",
    "    result[user_uid] = [int(ratings['element_uid'].cat.categories[i]) for i, _ in recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя только информацию о рейтингах мы смогли построить предсказание для `13251` из `50000` тестовых пользователей. Ровно в таком виде ответы и стоит сохранить для отправки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
