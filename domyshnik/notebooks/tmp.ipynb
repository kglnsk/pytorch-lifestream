{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model _params:\n",
      "        CURRENT_PARAMS cifar10_metric_learning_global_basis\n",
      "        N_AUGMENTS 5\n",
      "        LEARNING_RATE 0.002\n",
      "        GAMMA 0.9025\n",
      "        BATCH_SIZE 128\n",
      "        EPOCHS 50\n",
      "        SAMPLING_STRATEGY HardNegativePair\n",
      "        NEGATIVES_COUNT 5\n",
      "        MARGING 0.5\n",
      "        STEP_SIZE 5\n",
      "        MODEL_POSTFIX cifar10_global_c150_caug5_iaug5_cmrg05_imrg05_basis\n",
      "        ADD_INFO {'centroids_count': 150, 'losses': [{'name': 'BasisClusterisationLoss'}, {'name': 'ContrastiveLossOriginal_centroids', 'marging': 0.5, 'neg_count': 5, 'sampling_strategy': 'HardNegativePair'}, {'name': 'ContrastiveLossOriginal_images', 'marging': 0.5, 'neg_count': 5, 'sampling_strategy': 'HardNegativePairKlDiv'}], 'n_augs_imgs': 5}\n",
      "        ERROR_RATE 0.5\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/mnt/data/molchanov/dltranz')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function, Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from domyshnik.models import *\n",
    "from domyshnik.data import *\n",
    "from domyshnik.constants import *\n",
    "from domyshnik.utils import *\n",
    "from domyshnik.losses import *\n",
    "\n",
    "def draw(imgs):\n",
    "        if isinstance(imgs, list):\n",
    "            imgs = torch.stack(imgs)\n",
    "        fig = plt.figure()\n",
    "        rows, columns = 1, imgs.shape[0]\n",
    "        for i in range(imgs.shape[0]):\n",
    "            fig.add_subplot(rows, columns, i+1)\n",
    "            if imgs[i].size(0) == 3:\n",
    "                plt.imshow(imgs[i].transpose(0, 1).transpose(1, 2))\n",
    "            else:\n",
    "                plt.imshow(imgs[i])\n",
    "        plt.show()\n",
    "        \n",
    "def draw_rgb(imgs):\n",
    "    if isinstance(imgs, list):\n",
    "        imgs = torch.stack(imgs)\n",
    "    fig = plt.figure()\n",
    "    rows, columns = 1, imgs.shape[0]\n",
    "    for i in range(imgs.shape[0]):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(imgs[i].transpose(0, 1).transpose(1, 2))\n",
    "    plt.show()\n",
    "        \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2, 2, 3, 1],\n",
       "         [4, 3, 2, 3, 3]],\n",
       "\n",
       "        [[0, 1, 3, 0, 2],\n",
       "         [2, 2, 4, 3, 3]],\n",
       "\n",
       "        [[4, 1, 4, 0, 4],\n",
       "         [4, 4, 3, 2, 4]],\n",
       "\n",
       "        [[4, 2, 4, 4, 3],\n",
       "         [4, 4, 3, 0, 3]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.randint(0, 5, (4, 2, 5))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 3, 1],\n",
       "        [0, 1, 3, 0, 2],\n",
       "        [4, 1, 4, 0, 4],\n",
       "        [4, 2, 4, 4, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index_select(1, torch.Tensor([0]).long()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.random.randn(10, 10)\n",
    "t2 = np.random.randn(10, 10)\n",
    "np.concatenate((t1, t2), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3750)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([0.1, 0.2, 0.3, 0.5])\n",
    "h = F.softmax(x, dim=0) * F.log_softmax(x, dim=0)\n",
    "-h.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2599)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * torch.log(x)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n",
      "/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n",
      "/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1958: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.8129e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.randn(10) + 1\n",
    "F.kl_div(F.log_softmax(d), F.softmax(d), reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.zeros(150)\n",
    "t1[0] = 1.0\n",
    "t2 = torch.zeros(150)\n",
    "t2[1] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/mnt/data/molchanov/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0113)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.kl_div(F.log_softmax(t1), F.softmax(t2), reduction='none').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLpq = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
